{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "        import re\n",
    "        from collections import Counter\n",
    "\n",
    "        def load_custom_dictionary(text):\n",
    "            return re.findall(r'\\w+', text.lower())\n",
    "        \n",
    "        WORDS = Counter(load_custom_dictionary(open('chatbot_vocab.txt').read()))\n",
    "        def word_probablity(word, N=sum(WORDS.values())): \n",
    "            \"Probability of `word`.\"\n",
    "            return WORDS[word] / N\n",
    "        def correction(word): \n",
    "            \"Most probable spelling correction for word  wrt to custom dictionary \"\n",
    "            return max(possible_candidates(word), key=word_probablity)\n",
    "        def possible_candidates(word): \n",
    "            \"Generate possible spelling corrections for given word.\"\n",
    "            return (known([word]) or known(edits1(word)) or known(edits2(word)) or \n",
    "                [word])\n",
    "        def known(words): \n",
    "            \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "            return set(w for w in words if w in WORDS)\n",
    "        def edits1(word):\n",
    "            \"All edits that are one edit away from `word`.\"\n",
    "            letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "            splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "            deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "            transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "            replaces   = [L + c + R[1:]           for L, R in splits if R for c in \n",
    "                        letters]\n",
    "            inserts    = [L + c + R               for L, R in splits for c in \n",
    "            letters]\n",
    "            return set(deletes + transposes + replaces + inserts)\n",
    "        def edits2(word): \n",
    "            \"All edits that are two edits away from `word`.\"\n",
    "            return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "        def is_emoji(s):\n",
    "            return s in UNICODE_EMOJI\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have malaria\n"
     ]
    }
   ],
   "source": [
    "        sentence = \"i have maloria\"\n",
    "        string_split = sentence.split()\n",
    "        new_string = []\n",
    "        for i in string_split:\n",
    "#             if is_emoji(i):\n",
    "#                 word = UNICODE_EMOJI[i]\n",
    "#                 word = \" \".join(word.split(\":\")[1].split(\"_\"))\n",
    "#                 new_string.append(word)\n",
    "#             else:\n",
    "                new_string.append(i)\n",
    "                \n",
    "        new_sentence = \" \".join(new_string)\n",
    "        listofsentences = new_sentence.lower().split()\n",
    "        actual_message = []\n",
    "        for i in listofsentences:\n",
    "            actual_message.append(correction(i))\n",
    "        mesg = \" \".join(actual_message)  \n",
    "        print(mesg)          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
